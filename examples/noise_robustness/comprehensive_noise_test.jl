# Comprehensive Noise Robustness Test
# This demonstrates when adaptive loss outperforms RMSE

using LorenzParameterEstimation
using Random
using Statistics

println("ðŸ”Š Comprehensive Noise Robustness Analysis")
println("="^50)

true_params = L63Parameters(10.0, 28.0, 8/3)
initial_guess = L63Parameters(8.0, 25.0, 2.5)

println("True parameters: Ïƒ=10.0, Ï=28.0, Î²=2.667")
println("Initial guess: Ïƒ=8.0, Ï=25.0, Î²=2.5")
println()

# Test range of noise levels
noise_levels = [0.0, 0.02, 0.05, 0.1, 0.15, 0.2]

println("Noise Level â”‚ RMSE Loss      â”‚ MAE Loss       â”‚ Adaptive Loss  â”‚ Best Method")
println("           â”‚  Ïƒ    Error   â”‚  Ïƒ    Error   â”‚  Ïƒ    Error   â”‚")
println("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

for noise_level in noise_levels
    # Generate noisy data
    Random.seed!(42)  # Consistent results
    system = L63System(params=true_params, u0=[1.0, 1.0, 1.0], tspan=(0.0, 4.0), dt=0.01)
    solution = integrate(system)
    
    if noise_level > 0
        signal_std = std(solution.u)
        noise_std = noise_level * signal_std
        solution.u .+= randn(size(solution.u)) * noise_std
    end
    
    # Test RMSE
    results_rmse = modular_train!(
        deepcopy(initial_guess), solution,
        optimizer_config = adam_config(learning_rate=5e-3),
        loss_function = window_rmse,
        epochs = 40, window_size = 120, verbose = false
    )
    
    # Test MAE
    results_mae = modular_train!(
        deepcopy(initial_guess), solution,
        optimizer_config = adam_config(learning_rate=5e-3),
        loss_function = window_mae,
        epochs = 40, window_size = 120, verbose = false
    )
    
    # Test Adaptive
    results_adaptive = modular_train!(
        deepcopy(initial_guess), solution,
        optimizer_config = adam_config(learning_rate=5e-3),
        loss_function = adaptive_loss,
        epochs = 40, window_size = 120, verbose = false
    )
    
    # Calculate errors
    rmse_error = abs(results_rmse.best_params.Ïƒ - 10.0)
    mae_error = abs(results_mae.best_params.Ïƒ - 10.0)
    adaptive_error = abs(results_adaptive.best_params.Ïƒ - 10.0)
    
    # Find best method
    errors = [rmse_error, mae_error, adaptive_error]
    methods = ["RMSE", "MAE", "Adaptive"]
    best_idx = argmin(errors)
    best_method = methods[best_idx]
    
    println(@sprintf("   %4.2f    â”‚ %5.3f %5.3f â”‚ %5.3f %5.3f â”‚ %5.3f %5.3f â”‚ %s", 
            noise_level, 
            results_rmse.best_params.Ïƒ, rmse_error,
            results_mae.best_params.Ïƒ, mae_error,
            results_adaptive.best_params.Ïƒ, adaptive_error,
            best_method))
end

println()
println("ðŸ“Š Analysis:")
println("   â€¢ At low noise (â‰¤0.05): RMSE often performs well")
println("   â€¢ At high noise (â‰¥0.1): Adaptive/MAE should outperform RMSE")
println("   â€¢ Adaptive loss is robust to outliers caused by noise")
println()

# Demonstration with outliers
println("ðŸŽ¯ Outlier Robustness Test:")
println("="^30)

# Create data with deliberate outliers
Random.seed!(123)
system = L63System(params=true_params, u0=[1.0, 1.0, 1.0], tspan=(0.0, 3.0), dt=0.01)
outlier_solution = integrate(system)

# Add some extreme outliers (simulating measurement errors)
n_points = size(outlier_solution.u, 1)
n_outliers = max(1, round(Int, 0.02 * n_points))  # 2% outliers
outlier_indices = rand(1:n_points, n_outliers)

for idx in outlier_indices
    # Add large random spikes
    outlier_solution.u[idx, :] .+= randn(3) * 5.0
end

println("Added $(n_outliers) extreme outliers to simulate measurement errors...")

# Compare RMSE vs Adaptive on outlier data
results_rmse_outlier = modular_train!(
    deepcopy(initial_guess), outlier_solution,
    optimizer_config = adam_config(learning_rate=5e-3),
    loss_function = window_rmse,
    epochs = 50, window_size = 100, verbose = false
)

results_adaptive_outlier = modular_train!(
    deepcopy(initial_guess), outlier_solution,
    optimizer_config = adam_config(learning_rate=5e-3),
    loss_function = adaptive_loss,
    epochs = 50, window_size = 100, verbose = false
)

rmse_outlier_error = abs(results_rmse_outlier.best_params.Ïƒ - 10.0)
adaptive_outlier_error = abs(results_adaptive_outlier.best_params.Ïƒ - 10.0)

println("Results with outliers:")
println("RMSE:     Ïƒ=$(round(results_rmse_outlier.best_params.Ïƒ, digits=3)), error=$(round(rmse_outlier_error, digits=3))")
println("Adaptive: Ïƒ=$(round(results_adaptive_outlier.best_params.Ïƒ, digits=3)), error=$(round(adaptive_outlier_error, digits=3))")

if adaptive_outlier_error < rmse_outlier_error
    println("âœ… Adaptive loss is more robust to outliers!")
else
    println("âš ï¸  RMSE performed similarly (may need more outliers to see difference)")
end

println("\nðŸŽ‰ Noise robustness testing complete!")
println("ðŸ’¡ Use adaptive_loss when dealing with noisy or corrupted measurements.")